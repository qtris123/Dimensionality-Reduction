{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27d2e65",
   "metadata": {},
   "source": [
    "## Manifold Embedding Methods: General Framework\n",
    "\n",
    "Building a Neighborhood Graph\n",
    "### Goal: Capture local manifold structure usinig a weighted graph\n",
    "\n",
    "Step1: Construct an undirected graph where, nodes are the data points V and edges mean connecting \"nearby\" points using one of the following methods:\n",
    "\n",
    "1. epsilon-neighborhood graph: connected if satisfied a fixed-threshold distance and weighted by L2 norm of the difference vector.\n",
    "2. k-Nearest Neighbors (k-NN): each point is connected to its k nearest neighbors => More adaptive to varying data density (often more robust than fixed-threshold methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083df30e",
   "metadata": {},
   "source": [
    "### Why Graphs for Manifold Learning?\n",
    "Key insight:  Graph distances approximate geodesic distances on manifolds.\n",
    "If the graph is well-constructed, Shortest paths on the graph approximate geodesics on the manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc55d4",
   "metadata": {},
   "source": [
    "### Classifical Manifold Learning Methods (Brief Overview)\n",
    "\n",
    "Isomap (Isometric Feature Mapping)\n",
    "- Constructs k-NN graph\n",
    "- Computes shortest paths between all pairs using Dijkstra's or Floyd-Warshall\n",
    "- Applied MDS (Multidimensional Scaling) to the graph distance matrix\n",
    "- Limitation: Sensitive to noise and short-circuit edges\n",
    "\n",
    "Locally Linear Embedding (LLE)\n",
    "- Assumes each point is a linear combination of its neighbors\n",
    "- Preserves these linear relationships in low-dimensional space\n",
    "- Limitation: Can be unstable, requires careful parameter tuning\n",
    "\n",
    "Laplcaian Eigenmaps\n",
    "- Constructs graph Laplacian matrix\n",
    "- Low-dimensional embedding from smallest eigenvectors\n",
    "- Connection: Related to spectral clustering\n",
    "- Limitation: Eigendecomposition is expensive for large datasets\n",
    "\n",
    "t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "- Very popular for visualization (esp. in biology, NLP)\n",
    "- Preserves local neighborhoods using probability distributions\n",
    "- Uses Kullback-Leibler divergence as loss function\n",
    "- Limitations: Slow for large datasets; Doesn't preserve global structure well; Different runs can give different results; Difficult to tune perplexity parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a332b30b",
   "metadata": {},
   "source": [
    "### UMAP: Uniform Manifold Approximation and Porjection for Dimension Reduction\n",
    "(SOTA manifold embedding/clustering method)\n",
    "- Faster\n",
    "- Better Global Structure\n",
    "- General-purpose\n",
    "- Theoretical foundation\n",
    "- Consistent\n",
    "\n",
    "#### Step 1: Define Fuzzy Local Distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c86db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a776780",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2aba3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SuperResolution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
